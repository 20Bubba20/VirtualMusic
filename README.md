# VirtualMusic

Team Members: Jerron Pierro, Andra Williams, Morrell Waters, Cole Nardini

## Prerequisites

Python
MediaPipe
OpenCV-Python
imutils
cv2-enumerate-cameras

## Testing Directions

1. Download repository
2. Run detect_hands.py to test hand detection algorithm.
    - You can use n to switch to the next camera and you can quit using q or ESC
3. Run detect_gesture.py to test gesture detection algorithm.
4. Run app.py to test the completed app

## Milestone 1

Google Mediapipe integrated. 

   - Gesture detection and hand tracking both function but do not connect to much else yet.

Python library exploration.

   - What we can use for different aspect of our application.
   - Sound libraries, Mediapipe, GUI, etc.

Competition analysis.

   - What other products combine human motion and sound/music?
   - How do they perform this? How do they compare?

## Milestone 2

Hand detection is working.

   - Relevant points from the model can be obtained.

Camera switching.

   - If there is more than one camera device, the app can toggle between them.

Exploration into Godot.

   - Since PySimpleGUI is no longer being considered, perhaps something else would work better.
   - Godot has proven to have potential, but does not seem viable to switch to this late into the semester.
   - Another Python GUI library is a better choice.

## Milestone 3

## Milestone 4
